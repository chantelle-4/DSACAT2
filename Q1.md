a)Ignore Constants- Constants are ignored when analyzing algorithm efficiency, we only focus on how the time grows as input size increase (n). A number like 3 or 7 become insignificant for large inputs. Example:(O4n) will be simplified to O(n).

b)Focus on the dominant term- When an algorithm has multiple terms, the term with the highest growth rate determines the complexity. Example: O(n^2 + n) is simplified to O(n^2) because n^2 grows faster than n.

c)Iterative loops- For a single loop iterating n times will result to O(n) while a nested loop muliplies their complexities like:O(n*n) will result to O(n^2). Example for a single loop: for(int i=0, i<n; i++) { cout << "Bye" << endl; } Example for nested loop: for(int i=0, i<n; i++) { for (int j=0; j<n; j++) { cout << "Good morning" << endl; } }

d)Constant time operation- This is a simple operation that takes a fixed amount of time, regardless of the input size which are O(1). Example: When accessing an array element int x= arr[6];

e)Drop non-Dorminant terms- When analysing an algorithm's efficiency we only keep the term that grows faster because smaller terms become less important as n gets bigger. Example: O(n + n^2 + log n) a term like this we only focus on the term that grows faster so O(n^2) dominates because it increases much faster that O(n) and O(log n ) as n gets bigger. This will result us to drop O(n) and O(log n)cause there impact is minimal. The final complexity will be O(n^2).

